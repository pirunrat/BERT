
This is a BERT project, a state-of-the-art natural language processing (NLP) model developed by Google. BERT, short for Bidirectional Encoder Representations from Transformers, excels at understanding context and semantics in textual data.

In this project, a pre-trained model using BERT architecture was implemented in order to study how it actually works from scratch. The output of the system project is the percentage between two input sentences.

To utilize this application, you can simply clone or download the GitHub repository to your local machine and execute the Docker Compose configuration by right-clicking on the docker-compose.yaml file. This action will launch the application, allowing you to two sentences and analyze the match percentage for the two sentences.

![Alt text](./result.jpg)